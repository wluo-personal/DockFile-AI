{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T17:52:22.709257Z",
     "start_time": "2018-10-19T17:52:22.337548Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T17:52:22.721124Z",
     "start_time": "2018-10-19T17:52:22.711817Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/pima-indians-diabetes.data.csv',header=None)\n",
    "train_x = df.iloc[:,:8]\n",
    "train_y = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T17:52:27.964880Z",
     "start_time": "2018-10-19T17:52:22.722413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.619181\ttraining's binary_logloss: 0.619181\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's binary_logloss: 0.590036\ttraining's binary_logloss: 0.590036\n",
      "[3]\ttraining's binary_logloss: 0.569599\ttraining's binary_logloss: 0.569599\n",
      "[4]\ttraining's binary_logloss: 0.548104\ttraining's binary_logloss: 0.548104\n",
      "[5]\ttraining's binary_logloss: 0.531932\ttraining's binary_logloss: 0.531932\n",
      "[6]\ttraining's binary_logloss: 0.514285\ttraining's binary_logloss: 0.514285\n",
      "[7]\ttraining's binary_logloss: 0.501215\ttraining's binary_logloss: 0.501215\n",
      "[8]\ttraining's binary_logloss: 0.487854\ttraining's binary_logloss: 0.487854\n",
      "[9]\ttraining's binary_logloss: 0.475932\ttraining's binary_logloss: 0.475932\n",
      "[10]\ttraining's binary_logloss: 0.463826\ttraining's binary_logloss: 0.463826\n",
      "[11]\ttraining's binary_logloss: 0.452176\ttraining's binary_logloss: 0.452176\n",
      "[12]\ttraining's binary_logloss: 0.442396\ttraining's binary_logloss: 0.442396\n",
      "[13]\ttraining's binary_logloss: 0.433238\ttraining's binary_logloss: 0.433238\n",
      "[14]\ttraining's binary_logloss: 0.424871\ttraining's binary_logloss: 0.424871\n",
      "[15]\ttraining's binary_logloss: 0.417229\ttraining's binary_logloss: 0.417229\n",
      "[16]\ttraining's binary_logloss: 0.409365\ttraining's binary_logloss: 0.409365\n",
      "[17]\ttraining's binary_logloss: 0.402475\ttraining's binary_logloss: 0.402475\n",
      "[18]\ttraining's binary_logloss: 0.395925\ttraining's binary_logloss: 0.395925\n",
      "[19]\ttraining's binary_logloss: 0.389806\ttraining's binary_logloss: 0.389806\n",
      "[20]\ttraining's binary_logloss: 0.384433\ttraining's binary_logloss: 0.384433\n",
      "[21]\ttraining's binary_logloss: 0.378984\ttraining's binary_logloss: 0.378984\n",
      "[22]\ttraining's binary_logloss: 0.373718\ttraining's binary_logloss: 0.373718\n",
      "[23]\ttraining's binary_logloss: 0.368543\ttraining's binary_logloss: 0.368543\n",
      "[24]\ttraining's binary_logloss: 0.363548\ttraining's binary_logloss: 0.363548\n",
      "[25]\ttraining's binary_logloss: 0.359269\ttraining's binary_logloss: 0.359269\n",
      "[26]\ttraining's binary_logloss: 0.35528\ttraining's binary_logloss: 0.35528\n",
      "[27]\ttraining's binary_logloss: 0.350611\ttraining's binary_logloss: 0.350611\n",
      "[28]\ttraining's binary_logloss: 0.346917\ttraining's binary_logloss: 0.346917\n",
      "[29]\ttraining's binary_logloss: 0.342412\ttraining's binary_logloss: 0.342412\n",
      "[30]\ttraining's binary_logloss: 0.339217\ttraining's binary_logloss: 0.339217\n",
      "[31]\ttraining's binary_logloss: 0.334771\ttraining's binary_logloss: 0.334771\n",
      "[32]\ttraining's binary_logloss: 0.331891\ttraining's binary_logloss: 0.331891\n",
      "[33]\ttraining's binary_logloss: 0.32766\ttraining's binary_logloss: 0.32766\n",
      "[34]\ttraining's binary_logloss: 0.324628\ttraining's binary_logloss: 0.324628\n",
      "[35]\ttraining's binary_logloss: 0.320926\ttraining's binary_logloss: 0.320926\n",
      "[36]\ttraining's binary_logloss: 0.318404\ttraining's binary_logloss: 0.318404\n",
      "[37]\ttraining's binary_logloss: 0.315305\ttraining's binary_logloss: 0.315305\n",
      "[38]\ttraining's binary_logloss: 0.312262\ttraining's binary_logloss: 0.312262\n",
      "[39]\ttraining's binary_logloss: 0.308852\ttraining's binary_logloss: 0.308852\n",
      "[40]\ttraining's binary_logloss: 0.305799\ttraining's binary_logloss: 0.305799\n",
      "[41]\ttraining's binary_logloss: 0.302547\ttraining's binary_logloss: 0.302547\n",
      "[42]\ttraining's binary_logloss: 0.299746\ttraining's binary_logloss: 0.299746\n",
      "[43]\ttraining's binary_logloss: 0.296933\ttraining's binary_logloss: 0.296933\n",
      "[44]\ttraining's binary_logloss: 0.29469\ttraining's binary_logloss: 0.29469\n",
      "[45]\ttraining's binary_logloss: 0.291996\ttraining's binary_logloss: 0.291996\n",
      "[46]\ttraining's binary_logloss: 0.289542\ttraining's binary_logloss: 0.289542\n",
      "[47]\ttraining's binary_logloss: 0.2868\ttraining's binary_logloss: 0.2868\n",
      "[48]\ttraining's binary_logloss: 0.284878\ttraining's binary_logloss: 0.284878\n",
      "[49]\ttraining's binary_logloss: 0.281861\ttraining's binary_logloss: 0.281861\n",
      "[50]\ttraining's binary_logloss: 0.279193\ttraining's binary_logloss: 0.279193\n",
      "[51]\ttraining's binary_logloss: 0.276051\ttraining's binary_logloss: 0.276051\n",
      "[52]\ttraining's binary_logloss: 0.273291\ttraining's binary_logloss: 0.273291\n",
      "[53]\ttraining's binary_logloss: 0.270258\ttraining's binary_logloss: 0.270258\n",
      "[54]\ttraining's binary_logloss: 0.268411\ttraining's binary_logloss: 0.268411\n",
      "[55]\ttraining's binary_logloss: 0.266146\ttraining's binary_logloss: 0.266146\n",
      "[56]\ttraining's binary_logloss: 0.263496\ttraining's binary_logloss: 0.263496\n",
      "[57]\ttraining's binary_logloss: 0.260814\ttraining's binary_logloss: 0.260814\n",
      "[58]\ttraining's binary_logloss: 0.258661\ttraining's binary_logloss: 0.258661\n",
      "[59]\ttraining's binary_logloss: 0.256136\ttraining's binary_logloss: 0.256136\n",
      "[60]\ttraining's binary_logloss: 0.254075\ttraining's binary_logloss: 0.254075\n",
      "[61]\ttraining's binary_logloss: 0.252026\ttraining's binary_logloss: 0.252026\n",
      "[62]\ttraining's binary_logloss: 0.25018\ttraining's binary_logloss: 0.25018\n",
      "[63]\ttraining's binary_logloss: 0.247835\ttraining's binary_logloss: 0.247835\n",
      "[64]\ttraining's binary_logloss: 0.245745\ttraining's binary_logloss: 0.245745\n",
      "[65]\ttraining's binary_logloss: 0.243553\ttraining's binary_logloss: 0.243553\n",
      "[66]\ttraining's binary_logloss: 0.241696\ttraining's binary_logloss: 0.241696\n",
      "[67]\ttraining's binary_logloss: 0.239777\ttraining's binary_logloss: 0.239777\n",
      "[68]\ttraining's binary_logloss: 0.23751\ttraining's binary_logloss: 0.23751\n",
      "[69]\ttraining's binary_logloss: 0.235209\ttraining's binary_logloss: 0.235209\n",
      "[70]\ttraining's binary_logloss: 0.233544\ttraining's binary_logloss: 0.233544\n",
      "[71]\ttraining's binary_logloss: 0.231141\ttraining's binary_logloss: 0.231141\n",
      "[72]\ttraining's binary_logloss: 0.229667\ttraining's binary_logloss: 0.229667\n",
      "[73]\ttraining's binary_logloss: 0.227437\ttraining's binary_logloss: 0.227437\n",
      "[74]\ttraining's binary_logloss: 0.226028\ttraining's binary_logloss: 0.226028\n",
      "[75]\ttraining's binary_logloss: 0.223833\ttraining's binary_logloss: 0.223833\n",
      "[76]\ttraining's binary_logloss: 0.221828\ttraining's binary_logloss: 0.221828\n",
      "[77]\ttraining's binary_logloss: 0.219837\ttraining's binary_logloss: 0.219837\n",
      "[78]\ttraining's binary_logloss: 0.218006\ttraining's binary_logloss: 0.218006\n",
      "[79]\ttraining's binary_logloss: 0.216121\ttraining's binary_logloss: 0.216121\n",
      "[80]\ttraining's binary_logloss: 0.214957\ttraining's binary_logloss: 0.214957\n",
      "[81]\ttraining's binary_logloss: 0.2132\ttraining's binary_logloss: 0.2132\n",
      "[82]\ttraining's binary_logloss: 0.211526\ttraining's binary_logloss: 0.211526\n",
      "[83]\ttraining's binary_logloss: 0.209739\ttraining's binary_logloss: 0.209739\n",
      "[84]\ttraining's binary_logloss: 0.208551\ttraining's binary_logloss: 0.208551\n",
      "[85]\ttraining's binary_logloss: 0.206357\ttraining's binary_logloss: 0.206357\n",
      "[86]\ttraining's binary_logloss: 0.205141\ttraining's binary_logloss: 0.205141\n",
      "[87]\ttraining's binary_logloss: 0.203356\ttraining's binary_logloss: 0.203356\n",
      "[88]\ttraining's binary_logloss: 0.202351\ttraining's binary_logloss: 0.202351\n",
      "[89]\ttraining's binary_logloss: 0.200306\ttraining's binary_logloss: 0.200306\n",
      "[90]\ttraining's binary_logloss: 0.198935\ttraining's binary_logloss: 0.198935\n",
      "[91]\ttraining's binary_logloss: 0.197666\ttraining's binary_logloss: 0.197666\n",
      "[92]\ttraining's binary_logloss: 0.196377\ttraining's binary_logloss: 0.196377\n",
      "[93]\ttraining's binary_logloss: 0.1948\ttraining's binary_logloss: 0.1948\n",
      "[94]\ttraining's binary_logloss: 0.192742\ttraining's binary_logloss: 0.192742\n",
      "[95]\ttraining's binary_logloss: 0.191011\ttraining's binary_logloss: 0.191011\n",
      "[96]\ttraining's binary_logloss: 0.188959\ttraining's binary_logloss: 0.188959\n",
      "[97]\ttraining's binary_logloss: 0.186975\ttraining's binary_logloss: 0.186975\n",
      "[98]\ttraining's binary_logloss: 0.185961\ttraining's binary_logloss: 0.185961\n",
      "[99]\ttraining's binary_logloss: 0.184293\ttraining's binary_logloss: 0.184293\n",
      "[100]\ttraining's binary_logloss: 0.182811\ttraining's binary_logloss: 0.182811\n",
      "[101]\ttraining's binary_logloss: 0.181232\ttraining's binary_logloss: 0.181232\n",
      "[102]\ttraining's binary_logloss: 0.180289\ttraining's binary_logloss: 0.180289\n",
      "[103]\ttraining's binary_logloss: 0.178829\ttraining's binary_logloss: 0.178829\n",
      "[104]\ttraining's binary_logloss: 0.177149\ttraining's binary_logloss: 0.177149\n",
      "[105]\ttraining's binary_logloss: 0.175625\ttraining's binary_logloss: 0.175625\n",
      "[106]\ttraining's binary_logloss: 0.174241\ttraining's binary_logloss: 0.174241\n",
      "[107]\ttraining's binary_logloss: 0.172915\ttraining's binary_logloss: 0.172915\n",
      "[108]\ttraining's binary_logloss: 0.172024\ttraining's binary_logloss: 0.172024\n",
      "[109]\ttraining's binary_logloss: 0.170844\ttraining's binary_logloss: 0.170844\n",
      "[110]\ttraining's binary_logloss: 0.169727\ttraining's binary_logloss: 0.169727\n",
      "[111]\ttraining's binary_logloss: 0.168355\ttraining's binary_logloss: 0.168355\n",
      "[112]\ttraining's binary_logloss: 0.166765\ttraining's binary_logloss: 0.166765\n",
      "[113]\ttraining's binary_logloss: 0.165518\ttraining's binary_logloss: 0.165518\n",
      "[114]\ttraining's binary_logloss: 0.164283\ttraining's binary_logloss: 0.164283\n",
      "[115]\ttraining's binary_logloss: 0.162843\ttraining's binary_logloss: 0.162843\n",
      "[116]\ttraining's binary_logloss: 0.161908\ttraining's binary_logloss: 0.161908\n",
      "[117]\ttraining's binary_logloss: 0.160278\ttraining's binary_logloss: 0.160278\n",
      "[118]\ttraining's binary_logloss: 0.159472\ttraining's binary_logloss: 0.159472\n",
      "[119]\ttraining's binary_logloss: 0.158152\ttraining's binary_logloss: 0.158152\n",
      "[120]\ttraining's binary_logloss: 0.157266\ttraining's binary_logloss: 0.157266\n",
      "[121]\ttraining's binary_logloss: 0.156223\ttraining's binary_logloss: 0.156223\n",
      "[122]\ttraining's binary_logloss: 0.155039\ttraining's binary_logloss: 0.155039\n",
      "[123]\ttraining's binary_logloss: 0.153886\ttraining's binary_logloss: 0.153886\n",
      "[124]\ttraining's binary_logloss: 0.152283\ttraining's binary_logloss: 0.152283\n",
      "[125]\ttraining's binary_logloss: 0.151301\ttraining's binary_logloss: 0.151301\n",
      "[126]\ttraining's binary_logloss: 0.150376\ttraining's binary_logloss: 0.150376\n",
      "[127]\ttraining's binary_logloss: 0.149482\ttraining's binary_logloss: 0.149482\n",
      "[128]\ttraining's binary_logloss: 0.148602\ttraining's binary_logloss: 0.148602\n",
      "[129]\ttraining's binary_logloss: 0.147663\ttraining's binary_logloss: 0.147663\n",
      "[130]\ttraining's binary_logloss: 0.146893\ttraining's binary_logloss: 0.146893\n",
      "[131]\ttraining's binary_logloss: 0.145647\ttraining's binary_logloss: 0.145647\n",
      "[132]\ttraining's binary_logloss: 0.144889\ttraining's binary_logloss: 0.144889\n",
      "[133]\ttraining's binary_logloss: 0.143323\ttraining's binary_logloss: 0.143323\n",
      "[134]\ttraining's binary_logloss: 0.142504\ttraining's binary_logloss: 0.142504\n",
      "[135]\ttraining's binary_logloss: 0.141582\ttraining's binary_logloss: 0.141582\n",
      "[136]\ttraining's binary_logloss: 0.140521\ttraining's binary_logloss: 0.140521\n",
      "[137]\ttraining's binary_logloss: 0.139434\ttraining's binary_logloss: 0.139434\n",
      "[138]\ttraining's binary_logloss: 0.138655\ttraining's binary_logloss: 0.138655\n",
      "[139]\ttraining's binary_logloss: 0.137631\ttraining's binary_logloss: 0.137631\n",
      "[140]\ttraining's binary_logloss: 0.136689\ttraining's binary_logloss: 0.136689\n",
      "[141]\ttraining's binary_logloss: 0.135869\ttraining's binary_logloss: 0.135869\n",
      "[142]\ttraining's binary_logloss: 0.135177\ttraining's binary_logloss: 0.135177\n",
      "[143]\ttraining's binary_logloss: 0.134237\ttraining's binary_logloss: 0.134237\n",
      "[144]\ttraining's binary_logloss: 0.13324\ttraining's binary_logloss: 0.13324\n",
      "[145]\ttraining's binary_logloss: 0.132052\ttraining's binary_logloss: 0.132052\n",
      "[146]\ttraining's binary_logloss: 0.131386\ttraining's binary_logloss: 0.131386\n",
      "[147]\ttraining's binary_logloss: 0.130048\ttraining's binary_logloss: 0.130048\n",
      "[148]\ttraining's binary_logloss: 0.129272\ttraining's binary_logloss: 0.129272\n",
      "[149]\ttraining's binary_logloss: 0.127859\ttraining's binary_logloss: 0.127859\n",
      "[150]\ttraining's binary_logloss: 0.127156\ttraining's binary_logloss: 0.127156\n",
      "[151]\ttraining's binary_logloss: 0.126319\ttraining's binary_logloss: 0.126319\n",
      "[152]\ttraining's binary_logloss: 0.125769\ttraining's binary_logloss: 0.125769\n",
      "[153]\ttraining's binary_logloss: 0.124859\ttraining's binary_logloss: 0.124859\n",
      "[154]\ttraining's binary_logloss: 0.124227\ttraining's binary_logloss: 0.124227\n",
      "[155]\ttraining's binary_logloss: 0.123364\ttraining's binary_logloss: 0.123364\n",
      "[156]\ttraining's binary_logloss: 0.122269\ttraining's binary_logloss: 0.122269\n",
      "[157]\ttraining's binary_logloss: 0.121401\ttraining's binary_logloss: 0.121401\n",
      "[158]\ttraining's binary_logloss: 0.120707\ttraining's binary_logloss: 0.120707\n",
      "[159]\ttraining's binary_logloss: 0.119959\ttraining's binary_logloss: 0.119959\n",
      "[160]\ttraining's binary_logloss: 0.118917\ttraining's binary_logloss: 0.118917\n",
      "[161]\ttraining's binary_logloss: 0.117893\ttraining's binary_logloss: 0.117893\n",
      "[162]\ttraining's binary_logloss: 0.116851\ttraining's binary_logloss: 0.116851\n",
      "[163]\ttraining's binary_logloss: 0.115951\ttraining's binary_logloss: 0.115951\n",
      "[164]\ttraining's binary_logloss: 0.115192\ttraining's binary_logloss: 0.115192\n",
      "[165]\ttraining's binary_logloss: 0.114242\ttraining's binary_logloss: 0.114242\n",
      "[166]\ttraining's binary_logloss: 0.11354\ttraining's binary_logloss: 0.11354\n",
      "[167]\ttraining's binary_logloss: 0.112476\ttraining's binary_logloss: 0.112476\n",
      "[168]\ttraining's binary_logloss: 0.111956\ttraining's binary_logloss: 0.111956\n",
      "[169]\ttraining's binary_logloss: 0.110937\ttraining's binary_logloss: 0.110937\n",
      "[170]\ttraining's binary_logloss: 0.110318\ttraining's binary_logloss: 0.110318\n",
      "[171]\ttraining's binary_logloss: 0.109517\ttraining's binary_logloss: 0.109517\n",
      "[172]\ttraining's binary_logloss: 0.109077\ttraining's binary_logloss: 0.109077\n",
      "[173]\ttraining's binary_logloss: 0.108339\ttraining's binary_logloss: 0.108339\n",
      "[174]\ttraining's binary_logloss: 0.107774\ttraining's binary_logloss: 0.107774\n",
      "[175]\ttraining's binary_logloss: 0.106738\ttraining's binary_logloss: 0.106738\n",
      "[176]\ttraining's binary_logloss: 0.106022\ttraining's binary_logloss: 0.106022\n",
      "[177]\ttraining's binary_logloss: 0.105326\ttraining's binary_logloss: 0.105326\n",
      "[178]\ttraining's binary_logloss: 0.104855\ttraining's binary_logloss: 0.104855\n",
      "[179]\ttraining's binary_logloss: 0.103903\ttraining's binary_logloss: 0.103903\n",
      "[180]\ttraining's binary_logloss: 0.103384\ttraining's binary_logloss: 0.103384\n",
      "[181]\ttraining's binary_logloss: 0.102554\ttraining's binary_logloss: 0.102554\n",
      "[182]\ttraining's binary_logloss: 0.102115\ttraining's binary_logloss: 0.102115\n",
      "[183]\ttraining's binary_logloss: 0.1013\ttraining's binary_logloss: 0.1013\n",
      "[184]\ttraining's binary_logloss: 0.10086\ttraining's binary_logloss: 0.10086\n",
      "[185]\ttraining's binary_logloss: 0.10003\ttraining's binary_logloss: 0.10003\n",
      "[186]\ttraining's binary_logloss: 0.0992872\ttraining's binary_logloss: 0.0992872\n",
      "[187]\ttraining's binary_logloss: 0.0984357\ttraining's binary_logloss: 0.0984357\n",
      "[188]\ttraining's binary_logloss: 0.0978778\ttraining's binary_logloss: 0.0978778\n",
      "[189]\ttraining's binary_logloss: 0.0972469\ttraining's binary_logloss: 0.0972469\n",
      "[190]\ttraining's binary_logloss: 0.096308\ttraining's binary_logloss: 0.096308\n",
      "[191]\ttraining's binary_logloss: 0.0955722\ttraining's binary_logloss: 0.0955722\n",
      "[192]\ttraining's binary_logloss: 0.0950062\ttraining's binary_logloss: 0.0950062\n",
      "[193]\ttraining's binary_logloss: 0.0941995\ttraining's binary_logloss: 0.0941995\n",
      "[194]\ttraining's binary_logloss: 0.093598\ttraining's binary_logloss: 0.093598\n",
      "[195]\ttraining's binary_logloss: 0.0928565\ttraining's binary_logloss: 0.0928565\n",
      "[196]\ttraining's binary_logloss: 0.0921725\ttraining's binary_logloss: 0.0921725\n",
      "[197]\ttraining's binary_logloss: 0.0914171\ttraining's binary_logloss: 0.0914171\n",
      "[198]\ttraining's binary_logloss: 0.0907979\ttraining's binary_logloss: 0.0907979\n",
      "[199]\ttraining's binary_logloss: 0.0901034\ttraining's binary_logloss: 0.0901034\n",
      "[200]\ttraining's binary_logloss: 0.0897131\ttraining's binary_logloss: 0.0897131\n",
      "[201]\ttraining's binary_logloss: 0.08905\ttraining's binary_logloss: 0.08905\n",
      "[202]\ttraining's binary_logloss: 0.0884159\ttraining's binary_logloss: 0.0884159\n",
      "[203]\ttraining's binary_logloss: 0.0877644\ttraining's binary_logloss: 0.0877644\n",
      "[204]\ttraining's binary_logloss: 0.0871745\ttraining's binary_logloss: 0.0871745\n",
      "[205]\ttraining's binary_logloss: 0.0865857\ttraining's binary_logloss: 0.0865857\n",
      "[206]\ttraining's binary_logloss: 0.0861178\ttraining's binary_logloss: 0.0861178\n",
      "[207]\ttraining's binary_logloss: 0.0854569\ttraining's binary_logloss: 0.0854569\n",
      "[208]\ttraining's binary_logloss: 0.0848776\ttraining's binary_logloss: 0.0848776\n",
      "[209]\ttraining's binary_logloss: 0.0843149\ttraining's binary_logloss: 0.0843149\n",
      "[210]\ttraining's binary_logloss: 0.0835245\ttraining's binary_logloss: 0.0835245\n",
      "[211]\ttraining's binary_logloss: 0.0826921\ttraining's binary_logloss: 0.0826921\n",
      "[212]\ttraining's binary_logloss: 0.0821394\ttraining's binary_logloss: 0.0821394\n",
      "[213]\ttraining's binary_logloss: 0.0815609\ttraining's binary_logloss: 0.0815609\n",
      "[214]\ttraining's binary_logloss: 0.0811111\ttraining's binary_logloss: 0.0811111\n",
      "[215]\ttraining's binary_logloss: 0.0804676\ttraining's binary_logloss: 0.0804676\n",
      "[216]\ttraining's binary_logloss: 0.0799887\ttraining's binary_logloss: 0.0799887\n",
      "[217]\ttraining's binary_logloss: 0.0793527\ttraining's binary_logloss: 0.0793527\n",
      "[218]\ttraining's binary_logloss: 0.0788459\ttraining's binary_logloss: 0.0788459\n",
      "[219]\ttraining's binary_logloss: 0.0781795\ttraining's binary_logloss: 0.0781795\n",
      "[220]\ttraining's binary_logloss: 0.0777734\ttraining's binary_logloss: 0.0777734\n",
      "[221]\ttraining's binary_logloss: 0.0772345\ttraining's binary_logloss: 0.0772345\n",
      "[222]\ttraining's binary_logloss: 0.0766956\ttraining's binary_logloss: 0.0766956\n",
      "[223]\ttraining's binary_logloss: 0.076072\ttraining's binary_logloss: 0.076072\n",
      "[224]\ttraining's binary_logloss: 0.0755626\ttraining's binary_logloss: 0.0755626\n",
      "[225]\ttraining's binary_logloss: 0.0750571\ttraining's binary_logloss: 0.0750571\n",
      "[226]\ttraining's binary_logloss: 0.074613\ttraining's binary_logloss: 0.074613\n",
      "[227]\ttraining's binary_logloss: 0.0740941\ttraining's binary_logloss: 0.0740941\n",
      "[228]\ttraining's binary_logloss: 0.0735702\ttraining's binary_logloss: 0.0735702\n",
      "[229]\ttraining's binary_logloss: 0.0728738\ttraining's binary_logloss: 0.0728738\n",
      "[230]\ttraining's binary_logloss: 0.0724764\ttraining's binary_logloss: 0.0724764\n",
      "[231]\ttraining's binary_logloss: 0.071988\ttraining's binary_logloss: 0.071988\n",
      "[232]\ttraining's binary_logloss: 0.071474\ttraining's binary_logloss: 0.071474\n",
      "[233]\ttraining's binary_logloss: 0.0708973\ttraining's binary_logloss: 0.0708973\n",
      "[234]\ttraining's binary_logloss: 0.0703403\ttraining's binary_logloss: 0.0703403\n",
      "[235]\ttraining's binary_logloss: 0.06981\ttraining's binary_logloss: 0.06981\n",
      "[236]\ttraining's binary_logloss: 0.0692968\ttraining's binary_logloss: 0.0692968\n",
      "[237]\ttraining's binary_logloss: 0.0685976\ttraining's binary_logloss: 0.0685976\n",
      "[238]\ttraining's binary_logloss: 0.0680232\ttraining's binary_logloss: 0.0680232\n",
      "[239]\ttraining's binary_logloss: 0.0675868\ttraining's binary_logloss: 0.0675868\n",
      "[240]\ttraining's binary_logloss: 0.067072\ttraining's binary_logloss: 0.067072\n",
      "[241]\ttraining's binary_logloss: 0.0666192\ttraining's binary_logloss: 0.0666192\n",
      "[242]\ttraining's binary_logloss: 0.0661841\ttraining's binary_logloss: 0.0661841\n",
      "[243]\ttraining's binary_logloss: 0.0656911\ttraining's binary_logloss: 0.0656911\n",
      "[244]\ttraining's binary_logloss: 0.0652098\ttraining's binary_logloss: 0.0652098\n",
      "[245]\ttraining's binary_logloss: 0.0646297\ttraining's binary_logloss: 0.0646297\n",
      "[246]\ttraining's binary_logloss: 0.0642464\ttraining's binary_logloss: 0.0642464\n",
      "[247]\ttraining's binary_logloss: 0.0638585\ttraining's binary_logloss: 0.0638585\n",
      "[248]\ttraining's binary_logloss: 0.0633629\ttraining's binary_logloss: 0.0633629\n",
      "[249]\ttraining's binary_logloss: 0.0629084\ttraining's binary_logloss: 0.0629084\n",
      "[250]\ttraining's binary_logloss: 0.0625208\ttraining's binary_logloss: 0.0625208\n",
      "[251]\ttraining's binary_logloss: 0.0618655\ttraining's binary_logloss: 0.0618655\n",
      "[252]\ttraining's binary_logloss: 0.0613933\ttraining's binary_logloss: 0.0613933\n",
      "[253]\ttraining's binary_logloss: 0.0610413\ttraining's binary_logloss: 0.0610413\n",
      "[254]\ttraining's binary_logloss: 0.0606272\ttraining's binary_logloss: 0.0606272\n",
      "[255]\ttraining's binary_logloss: 0.0600929\ttraining's binary_logloss: 0.0600929\n",
      "[256]\ttraining's binary_logloss: 0.0597224\ttraining's binary_logloss: 0.0597224\n",
      "[257]\ttraining's binary_logloss: 0.0591687\ttraining's binary_logloss: 0.0591687\n",
      "[258]\ttraining's binary_logloss: 0.0587717\ttraining's binary_logloss: 0.0587717\n",
      "[259]\ttraining's binary_logloss: 0.0582094\ttraining's binary_logloss: 0.0582094\n",
      "[260]\ttraining's binary_logloss: 0.0578169\ttraining's binary_logloss: 0.0578169\n",
      "[261]\ttraining's binary_logloss: 0.0572589\ttraining's binary_logloss: 0.0572589\n",
      "[262]\ttraining's binary_logloss: 0.0569777\ttraining's binary_logloss: 0.0569777\n",
      "[263]\ttraining's binary_logloss: 0.0565156\ttraining's binary_logloss: 0.0565156\n",
      "[264]\ttraining's binary_logloss: 0.0560997\ttraining's binary_logloss: 0.0560997\n",
      "[265]\ttraining's binary_logloss: 0.0557745\ttraining's binary_logloss: 0.0557745\n",
      "[266]\ttraining's binary_logloss: 0.0554606\ttraining's binary_logloss: 0.0554606\n",
      "[267]\ttraining's binary_logloss: 0.0551574\ttraining's binary_logloss: 0.0551574\n",
      "[268]\ttraining's binary_logloss: 0.0548151\ttraining's binary_logloss: 0.0548151\n",
      "[269]\ttraining's binary_logloss: 0.0544454\ttraining's binary_logloss: 0.0544454\n",
      "[270]\ttraining's binary_logloss: 0.0542121\ttraining's binary_logloss: 0.0542121\n",
      "[271]\ttraining's binary_logloss: 0.0538157\ttraining's binary_logloss: 0.0538157\n",
      "[272]\ttraining's binary_logloss: 0.053452\ttraining's binary_logloss: 0.053452\n",
      "[273]\ttraining's binary_logloss: 0.0530136\ttraining's binary_logloss: 0.0530136\n",
      "[274]\ttraining's binary_logloss: 0.0526143\ttraining's binary_logloss: 0.0526143\n",
      "[275]\ttraining's binary_logloss: 0.0522563\ttraining's binary_logloss: 0.0522563\n",
      "[276]\ttraining's binary_logloss: 0.0519853\ttraining's binary_logloss: 0.0519853\n",
      "[277]\ttraining's binary_logloss: 0.0515975\ttraining's binary_logloss: 0.0515975\n",
      "[278]\ttraining's binary_logloss: 0.0512462\ttraining's binary_logloss: 0.0512462\n",
      "[279]\ttraining's binary_logloss: 0.0508482\ttraining's binary_logloss: 0.0508482\n",
      "[280]\ttraining's binary_logloss: 0.0502929\ttraining's binary_logloss: 0.0502929\n",
      "[281]\ttraining's binary_logloss: 0.0499519\ttraining's binary_logloss: 0.0499519\n",
      "[282]\ttraining's binary_logloss: 0.0496032\ttraining's binary_logloss: 0.0496032\n",
      "[283]\ttraining's binary_logloss: 0.0492938\ttraining's binary_logloss: 0.0492938\n",
      "[284]\ttraining's binary_logloss: 0.0489897\ttraining's binary_logloss: 0.0489897\n",
      "[285]\ttraining's binary_logloss: 0.0487036\ttraining's binary_logloss: 0.0487036\n",
      "[286]\ttraining's binary_logloss: 0.0484136\ttraining's binary_logloss: 0.0484136\n",
      "[287]\ttraining's binary_logloss: 0.0480939\ttraining's binary_logloss: 0.0480939\n",
      "[288]\ttraining's binary_logloss: 0.0477624\ttraining's binary_logloss: 0.0477624\n",
      "[289]\ttraining's binary_logloss: 0.0474287\ttraining's binary_logloss: 0.0474287\n",
      "[290]\ttraining's binary_logloss: 0.0471166\ttraining's binary_logloss: 0.0471166\n",
      "[291]\ttraining's binary_logloss: 0.0467955\ttraining's binary_logloss: 0.0467955\n",
      "[292]\ttraining's binary_logloss: 0.0465193\ttraining's binary_logloss: 0.0465193\n",
      "[293]\ttraining's binary_logloss: 0.046187\ttraining's binary_logloss: 0.046187\n",
      "[294]\ttraining's binary_logloss: 0.0459091\ttraining's binary_logloss: 0.0459091\n",
      "[295]\ttraining's binary_logloss: 0.0456271\ttraining's binary_logloss: 0.0456271\n",
      "[296]\ttraining's binary_logloss: 0.0453173\ttraining's binary_logloss: 0.0453173\n",
      "[297]\ttraining's binary_logloss: 0.0449415\ttraining's binary_logloss: 0.0449415\n",
      "[298]\ttraining's binary_logloss: 0.0447392\ttraining's binary_logloss: 0.0447392\n",
      "[299]\ttraining's binary_logloss: 0.0444286\ttraining's binary_logloss: 0.0444286\n",
      "[300]\ttraining's binary_logloss: 0.0441835\ttraining's binary_logloss: 0.0441835\n",
      "[301]\ttraining's binary_logloss: 0.0437526\ttraining's binary_logloss: 0.0437526\n",
      "[302]\ttraining's binary_logloss: 0.0434861\ttraining's binary_logloss: 0.0434861\n",
      "[303]\ttraining's binary_logloss: 0.0431044\ttraining's binary_logloss: 0.0431044\n",
      "[304]\ttraining's binary_logloss: 0.0426222\ttraining's binary_logloss: 0.0426222\n",
      "[305]\ttraining's binary_logloss: 0.042344\ttraining's binary_logloss: 0.042344\n",
      "[306]\ttraining's binary_logloss: 0.0421402\ttraining's binary_logloss: 0.0421402\n",
      "[307]\ttraining's binary_logloss: 0.041821\ttraining's binary_logloss: 0.041821\n",
      "[308]\ttraining's binary_logloss: 0.0415609\ttraining's binary_logloss: 0.0415609\n",
      "[309]\ttraining's binary_logloss: 0.0412149\ttraining's binary_logloss: 0.0412149\n",
      "[310]\ttraining's binary_logloss: 0.0409312\ttraining's binary_logloss: 0.0409312\n",
      "[311]\ttraining's binary_logloss: 0.0405182\ttraining's binary_logloss: 0.0405182\n",
      "[312]\ttraining's binary_logloss: 0.0403019\ttraining's binary_logloss: 0.0403019\n",
      "[313]\ttraining's binary_logloss: 0.0400085\ttraining's binary_logloss: 0.0400085\n",
      "[314]\ttraining's binary_logloss: 0.0397817\ttraining's binary_logloss: 0.0397817\n",
      "[315]\ttraining's binary_logloss: 0.0394558\ttraining's binary_logloss: 0.0394558\n",
      "[316]\ttraining's binary_logloss: 0.0392436\ttraining's binary_logloss: 0.0392436\n",
      "[317]\ttraining's binary_logloss: 0.0389637\ttraining's binary_logloss: 0.0389637\n",
      "[318]\ttraining's binary_logloss: 0.0387529\ttraining's binary_logloss: 0.0387529\n",
      "[319]\ttraining's binary_logloss: 0.0384372\ttraining's binary_logloss: 0.0384372\n",
      "[320]\ttraining's binary_logloss: 0.0381212\ttraining's binary_logloss: 0.0381212\n",
      "[321]\ttraining's binary_logloss: 0.0378055\ttraining's binary_logloss: 0.0378055\n",
      "[322]\ttraining's binary_logloss: 0.0375977\ttraining's binary_logloss: 0.0375977\n",
      "[323]\ttraining's binary_logloss: 0.0372068\ttraining's binary_logloss: 0.0372068\n",
      "[324]\ttraining's binary_logloss: 0.0368963\ttraining's binary_logloss: 0.0368963\n",
      "[325]\ttraining's binary_logloss: 0.0366195\ttraining's binary_logloss: 0.0366195\n",
      "[326]\ttraining's binary_logloss: 0.0364312\ttraining's binary_logloss: 0.0364312\n",
      "[327]\ttraining's binary_logloss: 0.0361489\ttraining's binary_logloss: 0.0361489\n",
      "[328]\ttraining's binary_logloss: 0.0359284\ttraining's binary_logloss: 0.0359284\n",
      "[329]\ttraining's binary_logloss: 0.0356624\ttraining's binary_logloss: 0.0356624\n",
      "[330]\ttraining's binary_logloss: 0.0354511\ttraining's binary_logloss: 0.0354511\n",
      "[331]\ttraining's binary_logloss: 0.0352178\ttraining's binary_logloss: 0.0352178\n",
      "[332]\ttraining's binary_logloss: 0.0349639\ttraining's binary_logloss: 0.0349639\n",
      "[333]\ttraining's binary_logloss: 0.0346562\ttraining's binary_logloss: 0.0346562\n",
      "[334]\ttraining's binary_logloss: 0.0344845\ttraining's binary_logloss: 0.0344845\n",
      "[335]\ttraining's binary_logloss: 0.0342005\ttraining's binary_logloss: 0.0342005\n",
      "[336]\ttraining's binary_logloss: 0.0340479\ttraining's binary_logloss: 0.0340479\n",
      "[337]\ttraining's binary_logloss: 0.033791\ttraining's binary_logloss: 0.033791\n",
      "[338]\ttraining's binary_logloss: 0.0335669\ttraining's binary_logloss: 0.0335669\n",
      "[339]\ttraining's binary_logloss: 0.0332323\ttraining's binary_logloss: 0.0332323\n",
      "[340]\ttraining's binary_logloss: 0.0330259\ttraining's binary_logloss: 0.0330259\n",
      "[341]\ttraining's binary_logloss: 0.0328174\ttraining's binary_logloss: 0.0328174\n",
      "[342]\ttraining's binary_logloss: 0.0325051\ttraining's binary_logloss: 0.0325051\n",
      "[343]\ttraining's binary_logloss: 0.0323059\ttraining's binary_logloss: 0.0323059\n",
      "[344]\ttraining's binary_logloss: 0.0321583\ttraining's binary_logloss: 0.0321583\n",
      "[345]\ttraining's binary_logloss: 0.0319546\ttraining's binary_logloss: 0.0319546\n",
      "[346]\ttraining's binary_logloss: 0.0318184\ttraining's binary_logloss: 0.0318184\n",
      "[347]\ttraining's binary_logloss: 0.0316365\ttraining's binary_logloss: 0.0316365\n",
      "[348]\ttraining's binary_logloss: 0.0314616\ttraining's binary_logloss: 0.0314616\n",
      "[349]\ttraining's binary_logloss: 0.0311742\ttraining's binary_logloss: 0.0311742\n",
      "[350]\ttraining's binary_logloss: 0.0310291\ttraining's binary_logloss: 0.0310291\n",
      "[351]\ttraining's binary_logloss: 0.0308638\ttraining's binary_logloss: 0.0308638\n",
      "[352]\ttraining's binary_logloss: 0.03075\ttraining's binary_logloss: 0.03075\n",
      "[353]\ttraining's binary_logloss: 0.0304922\ttraining's binary_logloss: 0.0304922\n",
      "[354]\ttraining's binary_logloss: 0.0303663\ttraining's binary_logloss: 0.0303663\n",
      "[355]\ttraining's binary_logloss: 0.0301209\ttraining's binary_logloss: 0.0301209\n",
      "[356]\ttraining's binary_logloss: 0.0299489\ttraining's binary_logloss: 0.0299489\n",
      "[357]\ttraining's binary_logloss: 0.02971\ttraining's binary_logloss: 0.02971\n",
      "[358]\ttraining's binary_logloss: 0.0295516\ttraining's binary_logloss: 0.0295516\n",
      "[359]\ttraining's binary_logloss: 0.0293452\ttraining's binary_logloss: 0.0293452\n",
      "[360]\ttraining's binary_logloss: 0.0292131\ttraining's binary_logloss: 0.0292131\n",
      "[361]\ttraining's binary_logloss: 0.0289339\ttraining's binary_logloss: 0.0289339\n",
      "[362]\ttraining's binary_logloss: 0.0287903\ttraining's binary_logloss: 0.0287903\n",
      "[363]\ttraining's binary_logloss: 0.0285922\ttraining's binary_logloss: 0.0285922\n",
      "[364]\ttraining's binary_logloss: 0.0284392\ttraining's binary_logloss: 0.0284392\n",
      "[365]\ttraining's binary_logloss: 0.0282207\ttraining's binary_logloss: 0.0282207\n",
      "[366]\ttraining's binary_logloss: 0.0280965\ttraining's binary_logloss: 0.0280965\n",
      "[367]\ttraining's binary_logloss: 0.0279135\ttraining's binary_logloss: 0.0279135\n",
      "[368]\ttraining's binary_logloss: 0.0277441\ttraining's binary_logloss: 0.0277441\n",
      "[369]\ttraining's binary_logloss: 0.0275759\ttraining's binary_logloss: 0.0275759\n",
      "[370]\ttraining's binary_logloss: 0.0274437\ttraining's binary_logloss: 0.0274437\n",
      "[371]\ttraining's binary_logloss: 0.0272414\ttraining's binary_logloss: 0.0272414\n",
      "[372]\ttraining's binary_logloss: 0.0271366\ttraining's binary_logloss: 0.0271366\n",
      "[373]\ttraining's binary_logloss: 0.0269231\ttraining's binary_logloss: 0.0269231\n",
      "[374]\ttraining's binary_logloss: 0.0268082\ttraining's binary_logloss: 0.0268082\n",
      "[375]\ttraining's binary_logloss: 0.0266537\ttraining's binary_logloss: 0.0266537\n",
      "[376]\ttraining's binary_logloss: 0.0265351\ttraining's binary_logloss: 0.0265351\n",
      "[377]\ttraining's binary_logloss: 0.0263511\ttraining's binary_logloss: 0.0263511\n",
      "[378]\ttraining's binary_logloss: 0.0262141\ttraining's binary_logloss: 0.0262141\n",
      "[379]\ttraining's binary_logloss: 0.0260195\ttraining's binary_logloss: 0.0260195\n",
      "[380]\ttraining's binary_logloss: 0.0259171\ttraining's binary_logloss: 0.0259171\n",
      "[381]\ttraining's binary_logloss: 0.0257014\ttraining's binary_logloss: 0.0257014\n",
      "[382]\ttraining's binary_logloss: 0.0255793\ttraining's binary_logloss: 0.0255793\n",
      "[383]\ttraining's binary_logloss: 0.0253728\ttraining's binary_logloss: 0.0253728\n",
      "[384]\ttraining's binary_logloss: 0.0252211\ttraining's binary_logloss: 0.0252211\n",
      "[385]\ttraining's binary_logloss: 0.0250178\ttraining's binary_logloss: 0.0250178\n",
      "[386]\ttraining's binary_logloss: 0.0248486\ttraining's binary_logloss: 0.0248486\n",
      "[387]\ttraining's binary_logloss: 0.0247084\ttraining's binary_logloss: 0.0247084\n",
      "[388]\ttraining's binary_logloss: 0.0245581\ttraining's binary_logloss: 0.0245581\n",
      "[389]\ttraining's binary_logloss: 0.0244255\ttraining's binary_logloss: 0.0244255\n",
      "[390]\ttraining's binary_logloss: 0.0242838\ttraining's binary_logloss: 0.0242838\n",
      "[391]\ttraining's binary_logloss: 0.0241289\ttraining's binary_logloss: 0.0241289\n",
      "[392]\ttraining's binary_logloss: 0.024\ttraining's binary_logloss: 0.024\n",
      "[393]\ttraining's binary_logloss: 0.0238368\ttraining's binary_logloss: 0.0238368\n",
      "[394]\ttraining's binary_logloss: 0.0237197\ttraining's binary_logloss: 0.0237197\n",
      "[395]\ttraining's binary_logloss: 0.0235703\ttraining's binary_logloss: 0.0235703\n",
      "[396]\ttraining's binary_logloss: 0.0234354\ttraining's binary_logloss: 0.0234354\n",
      "[397]\ttraining's binary_logloss: 0.0232426\ttraining's binary_logloss: 0.0232426\n",
      "[398]\ttraining's binary_logloss: 0.023143\ttraining's binary_logloss: 0.023143\n",
      "[399]\ttraining's binary_logloss: 0.0229675\ttraining's binary_logloss: 0.0229675\n",
      "[400]\ttraining's binary_logloss: 0.0228185\ttraining's binary_logloss: 0.0228185\n",
      "[401]\ttraining's binary_logloss: 0.0226736\ttraining's binary_logloss: 0.0226736\n",
      "[402]\ttraining's binary_logloss: 0.0224798\ttraining's binary_logloss: 0.0224798\n",
      "[403]\ttraining's binary_logloss: 0.022301\ttraining's binary_logloss: 0.022301\n",
      "[404]\ttraining's binary_logloss: 0.0221347\ttraining's binary_logloss: 0.0221347\n",
      "[405]\ttraining's binary_logloss: 0.0219652\ttraining's binary_logloss: 0.0219652\n",
      "[406]\ttraining's binary_logloss: 0.0218354\ttraining's binary_logloss: 0.0218354\n",
      "[407]\ttraining's binary_logloss: 0.0216739\ttraining's binary_logloss: 0.0216739\n",
      "[408]\ttraining's binary_logloss: 0.0215574\ttraining's binary_logloss: 0.0215574\n",
      "[409]\ttraining's binary_logloss: 0.0213667\ttraining's binary_logloss: 0.0213667\n",
      "[410]\ttraining's binary_logloss: 0.0212902\ttraining's binary_logloss: 0.0212902\n",
      "[411]\ttraining's binary_logloss: 0.0211515\ttraining's binary_logloss: 0.0211515\n",
      "[412]\ttraining's binary_logloss: 0.0210484\ttraining's binary_logloss: 0.0210484\n",
      "[413]\ttraining's binary_logloss: 0.0208855\ttraining's binary_logloss: 0.0208855\n",
      "[414]\ttraining's binary_logloss: 0.0207709\ttraining's binary_logloss: 0.0207709\n",
      "[415]\ttraining's binary_logloss: 0.0206491\ttraining's binary_logloss: 0.0206491\n",
      "[416]\ttraining's binary_logloss: 0.0205423\ttraining's binary_logloss: 0.0205423\n",
      "[417]\ttraining's binary_logloss: 0.0203865\ttraining's binary_logloss: 0.0203865\n",
      "[418]\ttraining's binary_logloss: 0.0202746\ttraining's binary_logloss: 0.0202746\n",
      "[419]\ttraining's binary_logloss: 0.0201126\ttraining's binary_logloss: 0.0201126\n",
      "[420]\ttraining's binary_logloss: 0.01998\ttraining's binary_logloss: 0.01998\n",
      "[421]\ttraining's binary_logloss: 0.0198432\ttraining's binary_logloss: 0.0198432\n",
      "[422]\ttraining's binary_logloss: 0.0197455\ttraining's binary_logloss: 0.0197455\n",
      "[423]\ttraining's binary_logloss: 0.0195451\ttraining's binary_logloss: 0.0195451\n",
      "[424]\ttraining's binary_logloss: 0.0194398\ttraining's binary_logloss: 0.0194398\n",
      "[425]\ttraining's binary_logloss: 0.0193048\ttraining's binary_logloss: 0.0193048\n",
      "[426]\ttraining's binary_logloss: 0.0192109\ttraining's binary_logloss: 0.0192109\n",
      "[427]\ttraining's binary_logloss: 0.0190308\ttraining's binary_logloss: 0.0190308\n",
      "[428]\ttraining's binary_logloss: 0.0189368\ttraining's binary_logloss: 0.0189368\n",
      "[429]\ttraining's binary_logloss: 0.0188079\ttraining's binary_logloss: 0.0188079\n",
      "[430]\ttraining's binary_logloss: 0.0186947\ttraining's binary_logloss: 0.0186947\n",
      "[431]\ttraining's binary_logloss: 0.0185174\ttraining's binary_logloss: 0.0185174\n",
      "[432]\ttraining's binary_logloss: 0.0183646\ttraining's binary_logloss: 0.0183646\n",
      "[433]\ttraining's binary_logloss: 0.0182427\ttraining's binary_logloss: 0.0182427\n",
      "[434]\ttraining's binary_logloss: 0.0181405\ttraining's binary_logloss: 0.0181405\n",
      "[435]\ttraining's binary_logloss: 0.0180228\ttraining's binary_logloss: 0.0180228\n",
      "[436]\ttraining's binary_logloss: 0.0179199\ttraining's binary_logloss: 0.0179199\n",
      "[437]\ttraining's binary_logloss: 0.0178116\ttraining's binary_logloss: 0.0178116\n",
      "[438]\ttraining's binary_logloss: 0.0176929\ttraining's binary_logloss: 0.0176929\n",
      "[439]\ttraining's binary_logloss: 0.0175619\ttraining's binary_logloss: 0.0175619\n",
      "[440]\ttraining's binary_logloss: 0.0174677\ttraining's binary_logloss: 0.0174677\n",
      "[441]\ttraining's binary_logloss: 0.0173445\ttraining's binary_logloss: 0.0173445\n",
      "[442]\ttraining's binary_logloss: 0.0172598\ttraining's binary_logloss: 0.0172598\n",
      "[443]\ttraining's binary_logloss: 0.0171416\ttraining's binary_logloss: 0.0171416\n",
      "[444]\ttraining's binary_logloss: 0.0170629\ttraining's binary_logloss: 0.0170629\n",
      "[445]\ttraining's binary_logloss: 0.016943\ttraining's binary_logloss: 0.016943\n",
      "[446]\ttraining's binary_logloss: 0.0168211\ttraining's binary_logloss: 0.0168211\n",
      "[447]\ttraining's binary_logloss: 0.0167042\ttraining's binary_logloss: 0.0167042\n",
      "[448]\ttraining's binary_logloss: 0.016605\ttraining's binary_logloss: 0.016605\n",
      "[449]\ttraining's binary_logloss: 0.0164776\ttraining's binary_logloss: 0.0164776\n",
      "[450]\ttraining's binary_logloss: 0.0163508\ttraining's binary_logloss: 0.0163508\n",
      "[451]\ttraining's binary_logloss: 0.0162517\ttraining's binary_logloss: 0.0162517\n",
      "[452]\ttraining's binary_logloss: 0.016178\ttraining's binary_logloss: 0.016178\n",
      "[453]\ttraining's binary_logloss: 0.0160408\ttraining's binary_logloss: 0.0160408\n",
      "[454]\ttraining's binary_logloss: 0.0159417\ttraining's binary_logloss: 0.0159417\n",
      "[455]\ttraining's binary_logloss: 0.0158386\ttraining's binary_logloss: 0.0158386\n",
      "[456]\ttraining's binary_logloss: 0.0157427\ttraining's binary_logloss: 0.0157427\n",
      "[457]\ttraining's binary_logloss: 0.0156106\ttraining's binary_logloss: 0.0156106\n",
      "[458]\ttraining's binary_logloss: 0.0155364\ttraining's binary_logloss: 0.0155364\n",
      "[459]\ttraining's binary_logloss: 0.0154102\ttraining's binary_logloss: 0.0154102\n",
      "[460]\ttraining's binary_logloss: 0.0153124\ttraining's binary_logloss: 0.0153124\n",
      "[461]\ttraining's binary_logloss: 0.0151553\ttraining's binary_logloss: 0.0151553\n",
      "[462]\ttraining's binary_logloss: 0.0150699\ttraining's binary_logloss: 0.0150699\n",
      "[463]\ttraining's binary_logloss: 0.0149359\ttraining's binary_logloss: 0.0149359\n",
      "[464]\ttraining's binary_logloss: 0.0148306\ttraining's binary_logloss: 0.0148306\n",
      "[465]\ttraining's binary_logloss: 0.0147313\ttraining's binary_logloss: 0.0147313\n",
      "[466]\ttraining's binary_logloss: 0.0146447\ttraining's binary_logloss: 0.0146447\n",
      "[467]\ttraining's binary_logloss: 0.0145518\ttraining's binary_logloss: 0.0145518\n",
      "[468]\ttraining's binary_logloss: 0.0144857\ttraining's binary_logloss: 0.0144857\n",
      "[469]\ttraining's binary_logloss: 0.0144157\ttraining's binary_logloss: 0.0144157\n",
      "[470]\ttraining's binary_logloss: 0.0143064\ttraining's binary_logloss: 0.0143064\n",
      "[471]\ttraining's binary_logloss: 0.0142307\ttraining's binary_logloss: 0.0142307\n",
      "[472]\ttraining's binary_logloss: 0.0141682\ttraining's binary_logloss: 0.0141682\n",
      "[473]\ttraining's binary_logloss: 0.0140782\ttraining's binary_logloss: 0.0140782\n",
      "[474]\ttraining's binary_logloss: 0.0139602\ttraining's binary_logloss: 0.0139602\n",
      "[475]\ttraining's binary_logloss: 0.0138349\ttraining's binary_logloss: 0.0138349\n",
      "[476]\ttraining's binary_logloss: 0.0137586\ttraining's binary_logloss: 0.0137586\n",
      "[477]\ttraining's binary_logloss: 0.0136902\ttraining's binary_logloss: 0.0136902\n",
      "[478]\ttraining's binary_logloss: 0.0136102\ttraining's binary_logloss: 0.0136102\n",
      "[479]\ttraining's binary_logloss: 0.0134917\ttraining's binary_logloss: 0.0134917\n",
      "[480]\ttraining's binary_logloss: 0.0134041\ttraining's binary_logloss: 0.0134041\n",
      "[481]\ttraining's binary_logloss: 0.0133247\ttraining's binary_logloss: 0.0133247\n",
      "[482]\ttraining's binary_logloss: 0.0132523\ttraining's binary_logloss: 0.0132523\n",
      "[483]\ttraining's binary_logloss: 0.0131549\ttraining's binary_logloss: 0.0131549\n",
      "[484]\ttraining's binary_logloss: 0.013105\ttraining's binary_logloss: 0.013105\n",
      "[485]\ttraining's binary_logloss: 0.0129992\ttraining's binary_logloss: 0.0129992\n",
      "[486]\ttraining's binary_logloss: 0.0129395\ttraining's binary_logloss: 0.0129395\n",
      "[487]\ttraining's binary_logloss: 0.0128408\ttraining's binary_logloss: 0.0128408\n",
      "[488]\ttraining's binary_logloss: 0.0127841\ttraining's binary_logloss: 0.0127841\n",
      "[489]\ttraining's binary_logloss: 0.0127078\ttraining's binary_logloss: 0.0127078\n",
      "[490]\ttraining's binary_logloss: 0.0126203\ttraining's binary_logloss: 0.0126203\n",
      "[491]\ttraining's binary_logloss: 0.012543\ttraining's binary_logloss: 0.012543\n",
      "[492]\ttraining's binary_logloss: 0.012463\ttraining's binary_logloss: 0.012463\n",
      "[493]\ttraining's binary_logloss: 0.012374\ttraining's binary_logloss: 0.012374\n",
      "[494]\ttraining's binary_logloss: 0.0123018\ttraining's binary_logloss: 0.0123018\n",
      "[495]\ttraining's binary_logloss: 0.0122106\ttraining's binary_logloss: 0.0122106\n",
      "[496]\ttraining's binary_logloss: 0.0121348\ttraining's binary_logloss: 0.0121348\n",
      "[497]\ttraining's binary_logloss: 0.0120361\ttraining's binary_logloss: 0.0120361\n",
      "[498]\ttraining's binary_logloss: 0.0119547\ttraining's binary_logloss: 0.0119547\n",
      "[499]\ttraining's binary_logloss: 0.0118179\ttraining's binary_logloss: 0.0118179\n",
      "[500]\ttraining's binary_logloss: 0.0117571\ttraining's binary_logloss: 0.0117571\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.0117571\ttraining's binary_logloss: 0.0117571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,\n",
       "        device='cpu', gpu_device_id=0, importance_type='split',\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=500,\n",
       "        n_jobs=12, num_leaves=16, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=-1, subsample=0.6,\n",
       "        subsample_for_bin=200000, subsample_freq=0, verbose=-1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(n_jobs=12,\n",
    "                        device='cpu',\n",
    "                        gpu_device_id=0,\n",
    "                    boosting_type='gbdt',\n",
    "                    num_leaves=16,\n",
    "                    max_depth=-1,\n",
    "                    learning_rate=0.1,\n",
    "                    n_estimators=500,\n",
    "                    colsample_bytree=0.6,\n",
    "                    subsample=0.6,\n",
    "                    silent=-1,\n",
    "                    verbose=-1)\n",
    "\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x,train_y)],  verbose=1,early_stopping_rounds=100,eval_metric='logloss' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6-CPU",
   "language": "python",
   "name": "python3.6-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
